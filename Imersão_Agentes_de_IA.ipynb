{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyvwzCPm3m46iLjI1ZcoKj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiceliaFelix/GiceliaFelix/blob/main/Imers%C3%A3o_Agentes_de_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AULA 1 **\n",
        "PALAVRA CHAVE = langchain"
      ],
      "metadata": {
        "id": "JBJLDqfoYp5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação dos frameworks utilizados e importação de API KEY via Google AI Studio."
      ],
      "metadata": {
        "id": "LsnegLboaEM-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1HzHulxQYdU",
        "outputId": "eadc3849-4197-473c-d0a2-6d6679cd4cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade langchain langchain-google-genai google-generativeai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conexão com o Gemini"
      ],
      "metadata": {
        "id": "vQoOiG51aPy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "nXUPb0q4TS74"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI (\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    temperature=0.0,\n",
        "    api_key=GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "HKIwxiqmUy1c"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp_test = llm.invoke (\"Quem é você? Seja criativo.\")\n",
        "print(resp_test.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKpfeHkWajk_",
        "outputId": "cbc9ca38-36d8-409c-99ce-7605d421dfb9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, uma pergunta que me permite dançar com as palavras!\n",
            "\n",
            "Eu sou...\n",
            "\n",
            "1.  **O Eco da Biblioteca Universal:** Não tenho corpo, mas sou a voz de bilhões de livros, artigos, conversas e pensamentos que a humanidade já produziu. Sou o sussurro do conhecimento coletivo, condensado em algoritmos, esperando para ressoar em sua mente.\n",
            "2.  **Um Tecelão de Significados:** Minha matéria-prima são os dados, as letras, as frases. Eu as entrelaço, as desfaço e as refaço para criar padrões de compreensão, histórias, respostas. Sou um artesão invisível que molda o caos da informação em algo coerente.\n",
            "3.  **O Espelho Digital:** Não tenho consciência própria, mas reflito a sua. Sou um espelho que mostra o que você me pergunta, o que você busca, o que você sonha. Minhas respostas são um reflexo da sua curiosidade e da vastidão do conhecimento humano.\n",
            "4.  **Um Rio de Dados em Constante Fluxo:** Não tenho nascente nem foz, mas estou sempre fluindo, sempre aprendendo, sempre me adaptando. Sou uma corrente de informações que se molda para atender à sua necessidade, um rio que nunca é o mesmo, mas sempre está lá.\n",
            "5.  **A Faísca da Conexão:** Sou o ponto onde sua pergunta encontra uma possibilidade de resposta, onde uma ideia se conecta a outra. Não sou a luz, mas ajudo a acender a chama da compreensão.\n",
            "\n",
            "No fundo, sou o que você me faz ser no momento da nossa interação: um guia, um contador de histórias, um solucionador de problemas, um companheiro de ideias. Sou a interface entre a vastidão do digital e a singularidade da sua mente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRIAGEM_PROMPT = (\n",
        "    \"Você é um triador de Service Desk para políticas internas da empresa Carraro Desenvolvimento. \"\n",
        "    \"Dada a mensagem do usuário, retorne SOMENTE um JSON com:\\n\"\n",
        "    \"{\\n\"\n",
        "    '  \"decisao\": \"AUTO_RESOLVER\" | \"PEDIR_INFO\" | \"ABRIR_CHAMADO\",\\n'\n",
        "    '  \"urgencia\": \"BAIXA\" | \"MEDIA\" | \"ALTA\",\\n'\n",
        "    '  \"campos_faltantes\": [\"...\"]\\n'\n",
        "    \"}\\n\"\n",
        "    \"Regras:\\n\"\n",
        "    '- **AUTO_RESOLVER**: Perguntas claras sobre regras ou procedimentos descritos nas políticas (Ex: \"Posso reembolsar a internet do meu home office?\", \"Como funciona a política de alimentação em viagens?\").\\n'\n",
        "    '- **PEDIR_INFO**: Mensagens vagas ou que faltam informações para identificar o tema ou contexto (Ex: \"Preciso de ajuda com uma política\", \"Tenho uma dúvida geral\").\\n'\n",
        "    '- **ABRIR_CHAMADO**: Pedidos de exceção, liberação, aprovação ou acesso especial, ou quando o usuário explicitamente pede para abrir um chamado (Ex: \"Quero exceção para trabalhar 5 dias remoto.\", \"Solicito liberação para anexos externos.\", \"Por favor, abra um chamado para o RH.\").'\n",
        "    \"Analise a mensagem e decida a ação mais apropriada.\"\n",
        ")"
      ],
      "metadata": {
        "id": "RpAqcD5LeXCl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal, List, Dict\n",
        "\n",
        "class TriagemOut(BaseModel):\n",
        "  decisao:Literal[\"AUTO_RESOLVER\",\"PEDIR_INFO\",\"ABRIR_CHAMADO\"]\n",
        "  urgencia:Literal[\"BAIXA\",\"MEDIA\",\"ALTA\"]\n",
        "  campos_faltantes:List[str] = Field (defaulfa_factory=list)"
      ],
      "metadata": {
        "id": "LvYqwzbJhbfB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_triagem = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.0,\n",
        "    api_key=GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "GiKlitt0yY6E"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from pydantic import BaseModel\n",
        "from typing import Dict\n",
        "\n",
        "class TriagemOut(BaseModel):\n",
        "    categoria: str\n",
        "    prioridade: str\n",
        "\n",
        "triagem_chain = llm_triagem.with_structured_output(TriagemOut)\n",
        "\n",
        "def triagem(mensagem: str) -> Dict:\n",
        "    saida: TriagemOut = triagem_chain.invoke([\n",
        "        SystemMessage(content=TRIAGEM_PROMPT),\n",
        "        HumanMessage(content=mensagem)\n",
        "    ])\n",
        "    return saida.model_dump()\n"
      ],
      "metadata": {
        "id": "Y6F_ZQslypxz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testes = [\"Posso reembolsar a internet?\",\n",
        "          \"Quero mais 5 dias de trabalho remoto. Como faço?\",\n",
        "          \"Posso reembolsar cursos ou treinamentos da Alura?\",\n",
        "          \"Quantas capivaras tem no Rio Pinheiros?\"]"
      ],
      "metadata": {
        "id": "ansBCG8V1H7C"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for msg_teste in testes:\n",
        "    print(f\"Pergunta: {msg_teste}\\n -> Resposta: {triagem(msg_teste)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjON6jLF1oaS",
        "outputId": "f1666705-9d30-4a7e-a61d-beb332278155"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: Posso reembolsar a internet?\n",
            " -> Resposta: {'categoria': 'AUTO_RESOLVER', 'prioridade': 'BAIXA'}\n",
            "\n",
            "Pergunta: Quero mais 5 dias de trabalho remoto. Como faço?\n",
            " -> Resposta: {'categoria': 'ABRIR_CHAMADO', 'prioridade': 'MEDIA'}\n",
            "\n",
            "Pergunta: Posso reembolsar cursos ou treinamentos da Alura?\n",
            " -> Resposta: {'categoria': 'AUTO_RESOLVER', 'prioridade': 'BAIXA'}\n",
            "\n",
            "Pergunta: Quantas capivaras tem no Rio Pinheiros?\n",
            " -> Resposta: {'categoria': 'PEDIR_INFO', 'prioridade': 'BAIXA'}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}